import streamlit as st
import torch
import torch.nn as nn
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from torch.utils.data import Dataset, DataLoader
import plotly.graph_objects as go
from datetime import datetime, timedelta
import sqlite3
import json

DB_PATH = "predictions.db"

# =============== Database ===============
def init_db():
    conn = sqlite3.connect(DB_PATH)
    conn.execute('''CREATE TABLE IF NOT EXISTS predictions (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        symbol TEXT, model_type TEXT, run_date TEXT,
        pred_start_date TEXT, pred_end_date TEXT,
        predictions TEXT, seq_len INTEGER, pred_len INTEGER, epochs INTEGER
    )''')
    conn.execute('''CREATE TABLE IF NOT EXISTS actual_prices (
        symbol TEXT, date TEXT, close_price REAL,
        PRIMARY KEY (symbol, date)
    )''')
    conn.commit()
    conn.close()

def save_prediction(symbol, model_type, run_date, pred_start, pred_end, predictions, seq_len, pred_len, epochs):
    conn = sqlite3.connect(DB_PATH)
    conn.execute('''INSERT INTO predictions (symbol, model_type, run_date, pred_start_date, pred_end_date, predictions, seq_len, pred_len, epochs)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)''',
        (symbol, model_type, run_date, pred_start, pred_end, json.dumps(predictions), seq_len, pred_len, epochs))
    conn.commit()
    conn.close()

def save_actual_prices(symbol, df):
    conn = sqlite3.connect(DB_PATH)
    for _, row in df.iterrows():
        conn.execute('INSERT OR REPLACE INTO actual_prices (symbol, date, close_price) VALUES (?, ?, ?)',
            (symbol, str(row['time'])[:10], float(row['close'])))
    conn.commit()
    conn.close()

def get_predictions(symbol=None):
    conn = sqlite3.connect(DB_PATH)
    query = "SELECT * FROM predictions"
    if symbol:
        query += f" WHERE symbol = '{symbol}'"
    query += " ORDER BY run_date DESC"
    df = pd.read_sql_query(query, conn)
    conn.close()
    return df

def get_actual_prices(symbol, start_date, end_date):
    conn = sqlite3.connect(DB_PATH)
    df = pd.read_sql_query(f"SELECT * FROM actual_prices WHERE symbol = ? AND date BETWEEN ? AND ?",
        conn, params=(symbol, start_date, end_date))
    conn.close()
    return df

# =============== Models ===============
class NLinear(nn.Module):
    def __init__(self, seq_len, pred_len):
        super().__init__()
        self.linear = nn.Linear(seq_len, pred_len)
    
    def forward(self, x):
        seq_last = x[:, -1:, :].detach()
        x = x - seq_last
        x = self.linear(x.permute(0, 2, 1)).permute(0, 2, 1)
        return x + seq_last

class MovingAvg(nn.Module):
    def __init__(self, kernel_size):
        super().__init__()
        self.kernel_size = kernel_size
        self.avg = nn.AvgPool1d(kernel_size=kernel_size, stride=1, padding=0)
    
    def forward(self, x):
        front = x[:, 0:1, :].repeat(1, (self.kernel_size - 1) // 2, 1)
        end = x[:, -1:, :].repeat(1, (self.kernel_size - 1) // 2, 1)
        x = torch.cat([front, x, end], dim=1)
        return self.avg(x.permute(0, 2, 1)).permute(0, 2, 1)

class DLinear(nn.Module):
    def __init__(self, seq_len, pred_len, kernel_size=25):
        super().__init__()
        self.moving_avg = MovingAvg(kernel_size)
        self.linear_seasonal = nn.Linear(seq_len, pred_len)
        self.linear_trend = nn.Linear(seq_len, pred_len)
    
    def forward(self, x):
        trend = self.moving_avg(x)
        seasonal = x - trend
        trend_out = self.linear_trend(trend.permute(0, 2, 1)).permute(0, 2, 1)
        seasonal_out = self.linear_seasonal(seasonal.permute(0, 2, 1)).permute(0, 2, 1)
        return trend_out + seasonal_out

class LSTMModel(nn.Module):
    def __init__(self, seq_len, pred_len, hidden_size=64, num_layers=2):
        super().__init__()
        self.lstm = nn.LSTM(1, hidden_size, num_layers, batch_first=True, dropout=0.2)
        self.fc = nn.Linear(hidden_size, pred_len)
    
    def forward(self, x):
        out, _ = self.lstm(x)
        out = self.fc(out[:, -1, :])
        return out.unsqueeze(-1)

# =============== Dataset & Training ===============
class StockDataset(Dataset):
    def __init__(self, data, seq_len, pred_len):
        self.data, self.seq_len, self.pred_len = data, seq_len, pred_len
    
    def __len__(self):
        return len(self.data) - self.seq_len - self.pred_len + 1
    
    def __getitem__(self, idx):
        x = self.data[idx:idx + self.seq_len]
        y = self.data[idx + self.seq_len:idx + self.seq_len + self.pred_len]
        return torch.FloatTensor(x), torch.FloatTensor(y)

def train_model(model, train_loader, epochs, lr, progress_callback=None):
    criterion, optimizer = nn.MSELoss(), torch.optim.Adam(model.parameters(), lr=lr)
    for epoch in range(epochs):
        model.train()
        total_loss = sum(
            (optimizer.zero_grad(), loss := criterion(model(bx), by), loss.backward(), optimizer.step(), loss.item())[-1]
            for bx, by in train_loader
        )
        if progress_callback:
            progress_callback(epoch + 1, epochs, total_loss / len(train_loader))
    return model

@st.cache_data
def load_stock_data(symbol, start_date, end_date):
    from vnstock import Vnstock
    stock = Vnstock().stock(symbol=symbol, source='VCI')
    return stock.quote.history(start=start_date, end=end_date, interval='1D')

def create_model(model_type, seq_len, pred_len):
    models = {"NLinear": NLinear, "DLinear": DLinear, "LSTM": LSTMModel}
    return models[model_type](seq_len, pred_len)

# =============== Accuracy Calculation ===============
def calculate_accuracy(predictions, actuals):
    """Calculate MAPE and direction accuracy"""
    if len(actuals) == 0:
        return None, None
    pred_arr = np.array(predictions[:len(actuals)])
    actual_arr = np.array(actuals)
    mape = np.mean(np.abs((actual_arr - pred_arr) / actual_arr)) * 100
    direction_acc = np.mean((np.diff(pred_arr) > 0) == (np.diff(actual_arr) > 0)) * 100 if len(actual_arr) > 1 else None
    return mape, direction_acc

# =============== Streamlit App ===============
st.set_page_config(page_title="Stock Price Prediction", layout="wide")
init_db()

page = st.sidebar.radio("üìå Trang", ["D·ª± ƒëo√°n", "So s√°nh k·∫øt qu·∫£"])

if page == "D·ª± ƒëo√°n":
    st.title("üìà D·ª± ƒëo√°n gi√° c·ªï phi·∫øu")
    
    st.sidebar.header("‚öôÔ∏è C·∫•u h√¨nh")
    symbol = st.sidebar.text_input("M√£ c·ªï phi·∫øu", value="VNM")
    run_all = st.sidebar.checkbox("üîÑ Ch·∫°y c·∫£ 3 m√¥ h√¨nh", value=True)
    if not run_all:
        model_type = st.sidebar.selectbox("M√¥ h√¨nh", ["NLinear", "DLinear", "LSTM"])
    seq_len = st.sidebar.slider("S·ªë ng√†y lookback", 30, 120, 60)
    pred_len = st.sidebar.slider("S·ªë ng√†y d·ª± ƒëo√°n", 7, 60, 30)
    epochs = st.sidebar.slider("Epochs", 50, 300, 100)
    lr = st.sidebar.select_slider("Learning rate", options=[0.0001, 0.0005, 0.001, 0.005], value=0.001)

    if st.sidebar.button("üöÄ B·∫Øt ƒë·∫ßu d·ª± ƒëo√°n", type="primary"):
        try:
            with st.spinner("ƒêang t·∫£i d·ªØ li·ªáu..."):
                end_date = datetime.now().strftime('%Y-%m-%d')
                start_date = (datetime.now() - timedelta(days=365*3)).strftime('%Y-%m-%d')
                df = load_stock_data(symbol, start_date, end_date)
                save_actual_prices(symbol, df)
            
            st.success(f"‚úÖ ƒê√£ t·∫£i {len(df)} ng√†y d·ªØ li·ªáu c·ªßa {symbol}")
            
            prices = df['close'].values.reshape(-1, 1)
            scaler = MinMaxScaler()
            prices_scaled = scaler.fit_transform(prices)
            train_data = prices_scaled[:int(len(prices_scaled) * 0.8)]
            dataset = StockDataset(train_data, seq_len, pred_len)
            loader = DataLoader(dataset, batch_size=32, shuffle=True)
            
            models_to_run = ["NLinear", "DLinear", "LSTM"] if run_all else [model_type]
            results = {}
            
            last_date = pd.to_datetime(df['time'].iloc[-1])
            future_dates = pd.date_range(start=last_date + timedelta(days=1), periods=pred_len, freq='B')
            run_date = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            
            for mt in models_to_run:
                st.subheader(f"üîÑ Training {mt}")
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                def update_progress(epoch, total, loss):
                    progress_bar.progress(epoch / total)
                    status_text.text(f"Epoch {epoch}/{total} - Loss: {loss:.6f}")
                
                model = create_model(mt, seq_len, pred_len)
                model = train_model(model, loader, epochs, lr, update_progress)
                
                model.eval()
                with torch.no_grad():
                    last_seq = torch.FloatTensor(prices_scaled[-seq_len:]).unsqueeze(0)
                    prediction = model(last_seq).squeeze().numpy()
                prediction = scaler.inverse_transform(prediction.reshape(-1, 1)).flatten()
                results[mt] = prediction.tolist()
                
                save_prediction(symbol, mt, run_date, str(future_dates[0].date()), 
                    str(future_dates[-1].date()), prediction.tolist(), seq_len, pred_len, epochs)
                st.success(f"‚úÖ {mt} ho√†n t·∫•t!")
            
            # Plot all results
            st.subheader("üìä K·∫øt qu·∫£ d·ª± ƒëo√°n")
            fig = go.Figure()
            
            hist_df = df.tail(60)
            fig.add_trace(go.Scatter(x=hist_df['time'], y=hist_df['close'],
                mode='lines', name='Gi√° th·ª±c t·∫ø', line=dict(color='blue', width=2)))
            
            colors = {'NLinear': 'red', 'DLinear': 'green', 'LSTM': 'orange'}
            for mt, pred in results.items():
                fig.add_trace(go.Scatter(x=future_dates, y=pred,
                    mode='lines+markers', name=f'{mt}', line=dict(color=colors[mt], width=2, dash='dash')))
            
            fig.update_layout(title=f"D·ª± ƒëo√°n gi√° {symbol}", xaxis_title="Ng√†y", 
                yaxis_title="Gi√° (VND)", hovermode='x unified', height=500)
            st.plotly_chart(fig, use_container_width=True)
            
            # Summary table
            st.subheader("üìã So s√°nh d·ª± ƒëo√°n")
            summary_data = {'Ng√†y': future_dates.strftime('%Y-%m-%d')}
            for mt, pred in results.items():
                summary_data[mt] = [f"{p:,.0f}" for p in pred]
            st.dataframe(pd.DataFrame(summary_data), use_container_width=True)
            
        except Exception as e:
            st.error(f"‚ùå L·ªói: {str(e)}")

else:  # So s√°nh k·∫øt qu·∫£
    st.title("üìä So s√°nh k·∫øt qu·∫£ d·ª± ƒëo√°n v·ªõi th·ª±c t·∫ø")
    
    predictions_df = get_predictions()
    if predictions_df.empty:
        st.warning("Ch∆∞a c√≥ d·ªØ li·ªáu d·ª± ƒëo√°n. H√£y ch·∫°y d·ª± ƒëo√°n tr∆∞·ªõc!")
    else:
        symbols = predictions_df['symbol'].unique().tolist()
        selected_symbol = st.selectbox("Ch·ªçn m√£ c·ªï phi·∫øu", symbols)
        
        # Update actual prices
        if st.button("üîÑ C·∫≠p nh·∫≠t gi√° th·ª±c t·∫ø"):
            with st.spinner("ƒêang c·∫≠p nh·∫≠t..."):
                end_date = datetime.now().strftime('%Y-%m-%d')
                start_date = (datetime.now() - timedelta(days=365)).strftime('%Y-%m-%d')
                df = load_stock_data(selected_symbol, start_date, end_date)
                save_actual_prices(selected_symbol, df)
                st.success("‚úÖ ƒê√£ c·∫≠p nh·∫≠t gi√° th·ª±c t·∫ø!")
                st.rerun()
        
        symbol_preds = predictions_df[predictions_df['symbol'] == selected_symbol]
        run_dates = symbol_preds['run_date'].unique().tolist()
        selected_run = st.selectbox("Ch·ªçn l·∫ßn ch·∫°y", run_dates)
        
        run_preds = symbol_preds[symbol_preds['run_date'] == selected_run]
        
        # Get actual prices for comparison
        pred_start = run_preds['pred_start_date'].iloc[0]
        pred_end = run_preds['pred_end_date'].iloc[0]
        actual_df = get_actual_prices(selected_symbol, pred_start, pred_end)
        
        st.subheader("üìà Bi·ªÉu ƒë·ªì so s√°nh")
        fig = go.Figure()
        
        # Plot actual prices if available
        if not actual_df.empty:
            fig.add_trace(go.Scatter(x=actual_df['date'], y=actual_df['close_price'],
                mode='lines+markers', name='Gi√° th·ª±c t·∫ø', line=dict(color='blue', width=3)))
        
        # Plot predictions
        colors = {'NLinear': 'red', 'DLinear': 'green', 'LSTM': 'orange'}
        accuracy_results = []
        
        for _, row in run_preds.iterrows():
            mt = row['model_type']
            preds = json.loads(row['predictions'])
            dates = pd.date_range(start=row['pred_start_date'], periods=len(preds), freq='B')
            
            fig.add_trace(go.Scatter(x=dates, y=preds,
                mode='lines+markers', name=f'{mt} (d·ª± ƒëo√°n)', 
                line=dict(color=colors.get(mt, 'gray'), width=2, dash='dash')))
            
            # Calculate accuracy
            if not actual_df.empty:
                actual_prices = []
                for d in dates:
                    match = actual_df[actual_df['date'] == str(d.date())]
                    if not match.empty:
                        actual_prices.append(match['close_price'].iloc[0])
                
                if actual_prices:
                    mape, dir_acc = calculate_accuracy(preds, actual_prices)
                    accuracy_results.append({
                        'M√¥ h√¨nh': mt,
                        'MAPE (%)': f"{mape:.2f}" if mape else "N/A",
                        'Direction Accuracy (%)': f"{dir_acc:.2f}" if dir_acc else "N/A",
                        'S·ªë ng√†y so s√°nh': len(actual_prices)
                    })
        
        fig.update_layout(title=f"So s√°nh d·ª± ƒëo√°n vs th·ª±c t·∫ø - {selected_symbol}",
            xaxis_title="Ng√†y", yaxis_title="Gi√° (VND)", hovermode='x unified', height=500)
        st.plotly_chart(fig, use_container_width=True)
        
        # Accuracy table
        if accuracy_results:
            st.subheader("üìä ƒê·ªô ch√≠nh x√°c c√°c m√¥ h√¨nh")
            st.info("MAPE: Mean Absolute Percentage Error (c√†ng th·∫•p c√†ng t·ªët)\nDirection Accuracy: T·ª∑ l·ªá d·ª± ƒëo√°n ƒë√∫ng xu h∆∞·ªõng tƒÉng/gi·∫£m")
            acc_df = pd.DataFrame(accuracy_results)
            st.dataframe(acc_df, use_container_width=True)
            
            # Best model
            if len(accuracy_results) > 1:
                best = min(accuracy_results, key=lambda x: float(x['MAPE (%)']) if x['MAPE (%)'] != 'N/A' else float('inf'))
                st.success(f"üèÜ M√¥ h√¨nh t·ªët nh·∫•t (MAPE th·∫•p nh·∫•t): **{best['M√¥ h√¨nh']}** v·ªõi MAPE = {best['MAPE (%)']}%")
        else:
            st.warning("‚è≥ Ch∆∞a c√≥ d·ªØ li·ªáu gi√° th·ª±c t·∫ø ƒë·ªÉ so s√°nh. H√£y ƒë·ª£i ƒë·∫øn ng√†y d·ª± ƒëo√°n v√† c·∫≠p nh·∫≠t gi√°!")
        
        # Historical accuracy summary
        st.subheader("üìà T·ªïng h·ª£p ƒë·ªô ch√≠nh x√°c theo th·ªùi gian")
        all_accuracy = []
        for _, row in predictions_df[predictions_df['symbol'] == selected_symbol].iterrows():
            actual_df_hist = get_actual_prices(selected_symbol, row['pred_start_date'], row['pred_end_date'])
            if not actual_df_hist.empty:
                preds = json.loads(row['predictions'])
                dates = pd.date_range(start=row['pred_start_date'], periods=len(preds), freq='B')
                actual_prices = [actual_df_hist[actual_df_hist['date'] == str(d.date())]['close_price'].iloc[0] 
                    for d in dates if not actual_df_hist[actual_df_hist['date'] == str(d.date())].empty]
                if actual_prices:
                    mape, _ = calculate_accuracy(preds, actual_prices)
                    if mape:
                        all_accuracy.append({'Ng√†y ch·∫°y': row['run_date'], 'M√¥ h√¨nh': row['model_type'], 'MAPE (%)': mape})
        
        if all_accuracy:
            hist_df = pd.DataFrame(all_accuracy)
            fig2 = go.Figure()
            for mt in hist_df['M√¥ h√¨nh'].unique():
                mt_data = hist_df[hist_df['M√¥ h√¨nh'] == mt]
                fig2.add_trace(go.Scatter(x=mt_data['Ng√†y ch·∫°y'], y=mt_data['MAPE (%)'],
                    mode='lines+markers', name=mt))
            fig2.update_layout(title="MAPE theo th·ªùi gian", xaxis_title="Ng√†y ch·∫°y", yaxis_title="MAPE (%)", height=400)
            st.plotly_chart(fig2, use_container_width=True)
            
            # Average accuracy
            avg_acc = hist_df.groupby('M√¥ h√¨nh')['MAPE (%)'].mean().reset_index()
            avg_acc.columns = ['M√¥ h√¨nh', 'MAPE trung b√¨nh (%)']
            avg_acc = avg_acc.sort_values('MAPE trung b√¨nh (%)')
            st.dataframe(avg_acc, use_container_width=True)
            st.success(f"üèÜ M√¥ h√¨nh hi·ªáu qu·∫£ nh·∫•t t·ªïng th·ªÉ: **{avg_acc.iloc[0]['M√¥ h√¨nh']}**")

# Info section
with st.expander("‚ÑπÔ∏è H∆∞·ªõng d·∫´n"):
    st.markdown("""
    **Trang D·ª± ƒëo√°n**: Ch·∫°y d·ª± ƒëo√°n v·ªõi 1 ho·∫∑c c·∫£ 3 m√¥ h√¨nh, k·∫øt qu·∫£ ƒë∆∞·ª£c l∆∞u v√†o database.
    
    **Trang So s√°nh**: So s√°nh k·∫øt qu·∫£ d·ª± ƒëo√°n v·ªõi gi√° th·ª±c t·∫ø, t√≠nh ƒë·ªô ch√≠nh x√°c.
    
    **C√°c ch·ªâ s·ªë**:
    - MAPE: Sai s·ªë ph·∫ßn trƒÉm tuy·ªát ƒë·ªëi trung b√¨nh (c√†ng th·∫•p c√†ng t·ªët)
    - Direction Accuracy: T·ª∑ l·ªá d·ª± ƒëo√°n ƒë√∫ng xu h∆∞·ªõng tƒÉng/gi·∫£m
    
    ‚ö†Ô∏è **L∆∞u √Ω**: ƒê√¢y ch·ªâ l√† c√¥ng c·ª• tham kh·∫£o, kh√¥ng ph·∫£i khuy·∫øn ngh·ªã ƒë·∫ßu t∆∞.
    """)
